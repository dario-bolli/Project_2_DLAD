{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderDeeplabV3p(torch.nn.Module):\n",
    "    def __init__(self, bottleneck_ch, skip_4x_ch, num_out_ch):\n",
    "        super(DecoderDeeplabV3p, self).__init__()\n",
    "\n",
    "        # TODO: Implement a proper decoder with skip connections instead of the following\n",
    "        self.features_to_concatenation = torch.nn.Conv2d(bottleneck_ch, skip_4x_ch, kernel_size=1, stride=1)\n",
    "        self.concatenation_to_predictions = torch.nn.Conv2d(bottleneck_ch+skip_4x_ch, num_out_ch, kernel_size=3, stride=1)\n",
    "\n",
    "    def forward(self, features_bottleneck, features_skip_4x):\n",
    "        \"\"\"\n",
    "        DeepLabV3+ style decoder\n",
    "        :param features_bottleneck: bottleneck features of scale > 4\n",
    "        :param features_skip_4x: features of encoder of scale == 4\n",
    "        :return: features with 256 channels and the final tensor of predictions\n",
    "        \"\"\"\n",
    "        # TODO: Implement a proper decoder with skip connections instead of the following; keep returned\n",
    "        #       tensors in the same order and of the same shape.\n",
    "        #upsample ASPP features by 4\n",
    "        features_ASPP = F.interpolate(\n",
    "            features_bottleneck, size=features_skip_4x.shape[2:], mode='bilinear', align_corners=False\n",
    "        )\n",
    "        #1x1 conv2d on lowest feature (skip)\n",
    "        features_skip = self.features_to_concatenation(features_skip_4x)\n",
    "        #concatenation of lowest feature and upsampled output of ASPP\n",
    "        features_cat = torch.cat([features_skip,features_ASPP], dim=1)\n",
    "        #3x3 conv2d on concatenated features\n",
    "        predictions = concatenation_to_predictions(features_cat)\n",
    "        return predictions, features_cat\n",
    "\n",
    "\n",
    "\n",
    "class ASPPpart(torch.nn.Sequential):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation):\n",
    "        super().__init__(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=False),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "class ASPP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, rates=(3, 6, 9)):\n",
    "        super().__init__()\n",
    "        # TODO: Implement ASPP properly instead of the following\n",
    "        modules = []\n",
    "        rates = [2*x for x in rates]\n",
    "        modules.append(ASPPpart(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1))\n",
    "        for rate in rates:\n",
    "            modules.append(ASPPpart(in_channels, out_channels, kernel_size=3, stride=1, padding=rate, dilation=rate))\n",
    "       \n",
    "        #global_avg = torch.nn.AdaptiveAvgPool2d(1) does not work gives [256,512, H, W] instead of [256,256, H,W]\n",
    "        # therefore apply convolution with correct output channels\n",
    "        global_avg = torch.nn.Sequential(torch.nn.AdaptiveAvgPool2d(1),\n",
    "                                         torch.nn.Conv2d(in_channels, out_channels, kernel_size = 1))\n",
    "        modules.append(global_avg)\n",
    "        self.aspp_convs = torch.nn.ModuleList(modules)\n",
    "        print(\"In channels\", in_channels)\n",
    "        print(\"Out channels\", out_channels)\n",
    "        # At this stage when called, already concatenated so we know how many out channels we have for each conv.\n",
    "        # So total after concatenation of all diff layers of conv is len(self.aspp_convs)*out_channels\n",
    "        self.conv_1x1 = torch.nn.Conv2d(out_channels*len(self.aspp_convs), out_channels, kernel_size = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement ASPP properly instead of the following\n",
    "        res = []\n",
    "        resolution_h_w = (x.shape[2], x.shape[3]) # height and width of feature map image\n",
    "        for layer in self.aspp_convs:\n",
    "            res.append(layer(x))\n",
    "            print(layer)\n",
    "            print(\"Tensor size = \", layer(x).size())\n",
    "        #res[4] is the output of the average pooling but has h= 1, w = 1 so we upsample it to the needed height and width\n",
    "        res[4] = F.interpolate(res[4],resolution_h_w, mode = 'bilinear', align_corners=False)\n",
    "        res = torch.cat(res, dim = 1)\n",
    "        print(\"after cat\")\n",
    "        return self.conv_1x1(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In channels 512\n",
      "Out channels 256\n"
     ]
    }
   ],
   "source": [
    "aspp = ASPP(512,256) # instanciate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPPpart(\n",
      "  (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n",
      "Tensor size =  torch.Size([256, 256, 10, 10])\n",
      "ASPPpart(\n",
      "  (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n",
      "Tensor size =  torch.Size([256, 256, 10, 10])\n",
      "ASPPpart(\n",
      "  (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n",
      "Tensor size =  torch.Size([256, 256, 10, 10])\n",
      "ASPPpart(\n",
      "  (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n",
      "Tensor size =  torch.Size([256, 256, 10, 10])\n",
      "Sequential(\n",
      "  (0): AdaptiveAvgPool2d(output_size=1)\n",
      "  (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Tensor size =  torch.Size([256, 256, 1, 1])\n",
      "after cat\n",
      "return size of forward =  torch.Size([256, 256, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "features = torch.randn((256,512,10,10)) # format [BatchSize, Channels, Height, Width]\n",
    "features_tasks = aspp(features) # call forward method\n",
    "print(\"return size of forward = \", features_tasks.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderDeeplabV3p(256,64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 64 and 256 in dimension 0 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-53b4bc17f7ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions_4x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-2e5dd952100d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features_bottleneck, features_skip_4x)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mfeatures_skip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_to_concatenation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_skip_4x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#concatenation of lowest feature and upsampled output of ASPP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mfeatures_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_skip\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures_ASPP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#3x3 conv2d on concatenated features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenation_to_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 64 and 256 in dimension 0 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "predictions_4x, _ = decoder(features_tasks, torch.randn((64,256,10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
